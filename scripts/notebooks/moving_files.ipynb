{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_names = [\n",
    "    \"works\",\n",
    "    \"authors\",\n",
    "    \"sources\",\n",
    "    \"institutions\",\n",
    "    \"publishers\",\n",
    "    \"funders\",\n",
    "    \"concepts\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = Path(\"/home/hasone/code/ourresearch/openalex-docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "m = markdown.markdown(basedir.joinpath(\"SUMMARY.md\").read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /home/hasone/code/ourresearch/openalex-docs/scripts/markdown_edits.py\n",
    "\n",
    "DESCRIPTION = \"\"\"Make edits to Markdown docs, prioritizing making sure nothing is lost from original.\"\"\"\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Generator, List, Tuple\n",
    "import difflib\n",
    "import re\n",
    "\n",
    "import logging\n",
    "\n",
    "root_logger = logging.getLogger()\n",
    "logger = root_logger.getChild(__name__)\n",
    "\n",
    "# match (english-language) hashtags between 1 and 30 characters long\n",
    "# https://stackoverflow.com/questions/42065872/regex-for-a-valid-hashtag\n",
    "pattern_hashtag = re.compile(r\"(^|\\B)#(?![0-9_]+\\b)([a-zA-Z0-9_]{1,30})(\\b|\\r)\")\n",
    "\n",
    "\n",
    "class MarkdownDoc:\n",
    "    def __init__(\n",
    "        self,\n",
    "        txt: str,\n",
    "        parent: Any = None,\n",
    "    ) -> None:\n",
    "        # self.txt = txt\n",
    "        self.parent = parent\n",
    "\n",
    "        self.sections = [\n",
    "            MarkdownSection(sec, title, parent=self, level=2)\n",
    "            for title, sec in self.split_into_sections(txt, level=2)\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def txt(self):\n",
    "        return \"\\n\".join([section.txt for section in self.sections])\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        txt_repr = self.txt[:50] + \"...\" if len(self.txt) > 50 else self.txt\n",
    "        txt_repr = txt_repr.replace(\"\\n\", \"\\\\\")\n",
    "        return f\"{self.__class__}({txt_repr})\"\n",
    "\n",
    "    def get_section_by_title(self, title: str) -> \"MarkdownSection\":\n",
    "        s = [sec for sec in self.sections if sec.title.lower() == title.lower()]\n",
    "        if len(s) < 1:\n",
    "            raise KeyError(f\"could not find section with title {title}\")\n",
    "        elif len(s) > 1:\n",
    "            raise KeyError(f\"ERROR: more than one section found with title {title}\")\n",
    "        return s[0]\n",
    "\n",
    "    def split_into_sections(\n",
    "        self, markdown_text: str, level=2\n",
    "    ) -> Generator[Tuple[str, List[str]], None, None]:\n",
    "        \"\"\"This is a very simple way of splitting the markdown text into sections.\n",
    "        It will not handle edge cases very well.\n",
    "\n",
    "        Args:\n",
    "            markdown_text (str): full text in Markdown format\n",
    "            level (int, optional): Heading level to split by. Defaults to 2, meaning \"## <Heading label>\"\n",
    "\n",
    "        Yields:\n",
    "            Generator[Tuple[str, List[str]], None, None]: Tuple of (section title, list of lines)\n",
    "        \"\"\"\n",
    "        heading_indicator = \"#\" * level\n",
    "        protect_flag = False\n",
    "        # sections = OrderedDict()\n",
    "        this_section = []\n",
    "        this_section_title = \"\"\n",
    "        # this_section_txt = \"\"\n",
    "        for line in markdown_text.split(\"\\n\"):\n",
    "            if line.startswith(\"```\"):\n",
    "                protect_flag = not protect_flag\n",
    "            if protect_flag is False and line.startswith(heading_indicator + \" \"):\n",
    "                # sections.append(\"\\n\".join(this_section))\n",
    "                # sections[this_section_title] = \"\\n\".join(this_section)\n",
    "                # this_section_txt = \"\\n\".join(this_section)\n",
    "                yield this_section_title, this_section\n",
    "                this_section = [line]\n",
    "                this_section_title = line.strip(heading_indicator).strip()\n",
    "            else:\n",
    "                this_section.append(line)\n",
    "        # sections.append(\"\\n\".join(this_section))\n",
    "        # this_section_txt = \"\\n\".join(this_section)\n",
    "        yield this_section_title, this_section\n",
    "\n",
    "    def refresh_all_sections(self):\n",
    "        for sec in self.sections:\n",
    "            sec.refresh()\n",
    "\n",
    "\n",
    "class MarkdownSection:\n",
    "    def __init__(\n",
    "        self, lines: List[str], title: str = \"\", parent: Any = None, level=2\n",
    "    ) -> None:\n",
    "        self.lines = lines\n",
    "        self.title = title\n",
    "        self.parent = parent\n",
    "        self.level = level\n",
    "\n",
    "        self.refresh()\n",
    "\n",
    "    def refresh(self) -> None:\n",
    "        self.txt = \"\\n\".join(self.lines)\n",
    "        self.content = self.get_content()\n",
    "\n",
    "    def get_content(self) -> str:\n",
    "        content_lines = self.lines[1:]\n",
    "        content = \"\\n\".join(content_lines)\n",
    "        content = content.strip()\n",
    "        return content\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        txt_repr = self.txt[:50] + \"...\" if len(self.txt) > 50 else self.txt\n",
    "        txt_repr = txt_repr.replace(\"\\n\", \"\\\\\")\n",
    "        return f\"{self.__class__}({txt_repr})\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.txt\n",
    "\n",
    "    def get_resource_ids(self) -> List[str]:\n",
    "        # example of a resource id:\n",
    "        # \"![](:/f04c1849b3e64b5ca151a737720s0132)\"\n",
    "        return re.findall(r\"!\\[.*?\\]\\(:/([a-zA-Z0-9]+?)\\)\", self.content)\n",
    "\n",
    "    def update(self, new_txt: str, force: bool = False) -> str:\n",
    "        new_sec = MarkdownSection(new_txt.split(\"\\n\"))\n",
    "        if not new_sec.content or new_sec.content == \"None\":\n",
    "            # no new text to replace. do nothing\n",
    "            return \"no update\"\n",
    "        if self.txt == new_txt:\n",
    "            # new text is the same as old text. do nothing\n",
    "            return \"no update\"\n",
    "\n",
    "        if force is True:\n",
    "            replace = True\n",
    "        else:\n",
    "            replace = False\n",
    "            if not self.content or self.content == \"None\":\n",
    "                # no old text exists. safe to replace\n",
    "                replace = True\n",
    "            else:\n",
    "                s = difflib.SequenceMatcher(\n",
    "                    None, self.content.splitlines(), new_sec.content.splitlines()\n",
    "                )\n",
    "                tags = [opcode[0] for opcode in s.get_opcodes()]\n",
    "                if all(tag in [\"equal\", \"insert\"] for tag in tags):\n",
    "                    # no merge conflicts (no lines are marked to delete or replace). safe to replace old text with new text\n",
    "                    replace = True\n",
    "                else:\n",
    "                    logger.debug(tags)\n",
    "        if replace is True:\n",
    "            # self.txt = new_txt\n",
    "            self.lines = new_txt.split(\"\\n\")\n",
    "            # self.content = self.get_content()\n",
    "            self.refresh()\n",
    "            return \"updated\"\n",
    "\n",
    "        logger.debug(new_txt)\n",
    "        from difflib import Differ\n",
    "\n",
    "        logger.debug(MarkdownSection(new_txt.splitlines()).content)\n",
    "        for x in Differ().compare(self.lines, new_txt.splitlines()):\n",
    "            logger.debug(x)\n",
    "        raise RuntimeError(\"could not update text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarySection(MarkdownSection):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = MarkdownDoc(basedir.joinpath(\"SUMMARY.md\").read_text())\n",
    "api_section = md.get_section_by_title(\"The Api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(r\"^(\\s*)\")\n",
    "m = p.search(\"    * [Postgres schema diagram](the-data-snapshot/upload-to-your-database/load-to-a-relational-database/postgres-schema-diagram.md)\")\n",
    "len(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## The API\n",
      "\n",
      "* [API Overview](the-api/api-overview.md)\n",
      "* [Rate limits and authentication](the-api/rate-limits-and-authentication.md)\n",
      "* [Get single entities](the-api/get-single-entities/README.md)\n",
      "  * [Random result](the-api/get-single-entities/random-result.md)\n",
      "  * [Select fields](the-api/get-single-entities/select-fields.md)\n",
      "  * [Get a single work](the-api/get-single-entities/get-a-single-work.md)\n",
      "* [Get lists of entities](the-api/get-lists-of-entities/README.md)\n",
      "  * [Paging](the-api/get-lists-of-entities/paging.md)\n",
      "  * [Filter entity lists](the-api/get-lists-of-entities/filter-entity-lists.md)\n",
      "  * [Search entities](the-api/get-lists-of-entities/search-entities.md)\n",
      "  * [Sort entity lists](the-api/get-lists-of-entities/sort-entity-lists.md)\n",
      "  * [Select fields](the-api/get-lists-of-entities/select-fields.md)\n",
      "  * [Sample entity lists](the-api/get-lists-of-entities/sample-entity-lists.md)\n",
      "  * [Autocomplete entities](the-api/get-lists-of-entities/autocomplete-entities.md)\n",
      "  * [Get lists of works](the-api/get-lists-of-entities/get-lists-of-works.md)\n",
      "* [Get groups of entities](the-api/get-groups-of-entities/README.md)\n",
      "  * [Group works](the-api/get-groups-of-entities/group-works.md)\n",
      "* [Filters](the-api/filters/README.md)\n",
      "  * [Filter works](the-api/filters/filter-works.md)\n",
      "  * [Filter authors](the-api/filters/filter-authors.md)\n",
      "  * [Filter sources](the-api/filters/filter-sources.md)\n",
      "  * [Filter institutions](the-api/filters/filter-institutions.md)\n",
      "  * [Filter concepts](the-api/filters/filter-concepts.md)\n",
      "  * [Filter publishers](the-api/filters/filter-publishers.md)\n",
      "  *\n",
      "* [Search](the-api/search/README.md)\n",
      "  * [Search works](the-api/search/search-works.md)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(api_section.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving /home/hasone/code/ourresearch/openalex-docs/the-data/authors/group-authors.md to /home/hasone/code/ourresearch/openalex-docs/the-api/get-groups-of-entities/group-authors.md\n",
      "moving /home/hasone/code/ourresearch/openalex-docs/the-data/sources/group-sources.md to /home/hasone/code/ourresearch/openalex-docs/the-api/get-groups-of-entities/group-sources.md\n",
      "moving /home/hasone/code/ourresearch/openalex-docs/the-data/institutions/group-institutions.md to /home/hasone/code/ourresearch/openalex-docs/the-api/get-groups-of-entities/group-institutions.md\n",
      "moving /home/hasone/code/ourresearch/openalex-docs/the-data/publishers/group-publishers.md to /home/hasone/code/ourresearch/openalex-docs/the-api/get-groups-of-entities/group-publishers.md\n",
      "moving /home/hasone/code/ourresearch/openalex-docs/the-data/funders/group-funders.md to /home/hasone/code/ourresearch/openalex-docs/the-api/get-groups-of-entities/group-funders.md\n",
      "moving /home/hasone/code/ourresearch/openalex-docs/the-data/concepts/group-concepts.md to /home/hasone/code/ourresearch/openalex-docs/the-api/get-groups-of-entities/group-concepts.md\n"
     ]
    }
   ],
   "source": [
    "for entity_name in entity_names:\n",
    "    entity_dir = basedir.joinpath(f\"the-data/{entity_name}\")\n",
    "    fp = entity_dir.joinpath(f\"group-{entity_name}.md\")\n",
    "    if fp.exists():\n",
    "        dest = basedir.joinpath(f\"the-api/get-groups-of-entities/group-{entity_name}.md\")\n",
    "        # if not dest.exists():\n",
    "        print(f\"moving {fp} to {dest}\")\n",
    "        shutil.move(fp, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/hasone/code/ourresearch/openalex-docs/the-data/concepts')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
